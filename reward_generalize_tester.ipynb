{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reward_generalize_tester.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmAWkB6AnGMBAOhz7Os32Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/platers/meta-transfer-learning/blob/master/reward_generalize_tester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1_rXeUkpm5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXgxK9Z4sdon",
        "colab_type": "code",
        "outputId": "fb57be51-f2ed-4c2b-c205-37067b213483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "class TransferTestEnv(gym.Env):\n",
        "  def __init__(self, bg_color, agent_color):\n",
        "    self.bg_color = bg_color\n",
        "    self.agent_color = agent_color\n",
        "    self.color_num = 1\n",
        "    self.env_size = 5\n",
        "    pass\n",
        "\n",
        "  def reset(self):\n",
        "    self.location = np.random.randint(0, self.env_size, [2])\n",
        "    color_extra_dim = np.reshape(self.bg_color, [1,1,self.color_num])\n",
        "    state = np.tile(color_extra_dim, [self.env_size, self.env_size, self.color_num])\n",
        "\n",
        "    state[self.location[0], self.location[1]] = self.agent_color\n",
        "\n",
        "    reward = self.location[0] + self.location[1]\n",
        "\n",
        "    return state, reward\n",
        "\n",
        "state, reward = TransferTestEnv(5, 1).reset()\n",
        "plt.imshow(np.squeeze(state))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa384cbfb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s0L2_CPnOyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(dataset_size, env_params):\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for _ in range(dataset_size):\n",
        "    state, reward = TransferTestEnv(*env_params).reset()\n",
        "    xs.append(state)\n",
        "    ys.append(reward)\n",
        "\n",
        "  xs = np.array(xs)\n",
        "  ys = np.array(ys)\n",
        "\n",
        "  return xs, ys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTIVmjItrfTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs, ys = generate_data(1000, (5,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x41hWLM75Bvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=xs.shape[1:]),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64),\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-99yNTCp6dU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23a322c3-fc8e-48f6-b005-147b16878a8f"
      },
      "source": [
        "model.fit(xs, ys, epochs=100)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.1048\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0986\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0941\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0813\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0789\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0695\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0629\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0568\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0546\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0482\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0465\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0428\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0396\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0355\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0326\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0303\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0267\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0254\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0243\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0219\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0248\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0178\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0165\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0153\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0130\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0138\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0117\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0094\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0050\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0044\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0039\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0035\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0034\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0029\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0025\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0023\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0022\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0018\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0017\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0010\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 9.9827e-04\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 8.5454e-04\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 7.1468e-04\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 6.3282e-04\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 5.6500e-04\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 5.8272e-04\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 4.8503e-04\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 4.5975e-04\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 3.9734e-04\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 4.2579e-04\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 3.4793e-04\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.7981e-04\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.7721e-04\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.4309e-04\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.0892e-04\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.9435e-04\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.7913e-04\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.6198e-04\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.4950e-04\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.2079e-04\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.1083e-04\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.0658e-04\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.0161e-04\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 8.5437e-05\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 7.6810e-05\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 6.5461e-05\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 6.1336e-05\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 5.1641e-05\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 4.7699e-05\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 4.0965e-05\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 4.1043e-05\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 3.5363e-05\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.0905e-05\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.9061e-05\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.6331e-05\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.2230e-05\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.0195e-05\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 2.0180e-05\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.6464e-05\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.7048e-05\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.1671e-05\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.1155e-05\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 9.6472e-06\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.0005e-05\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 8.6216e-06\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 7.2047e-06\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 6.8522e-06\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 5.2553e-06\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 4.8536e-06\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 5.8168e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa3397725c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bR6KhNrtrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs_val, ys_val = generate_data(1000, (5,1))\n",
        "xs_val_differnt, ys_val_different = generate_data(1000, (4,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2yFqMl3r8Us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6d24263c-2f99-430c-819e-46aa74f74bbe"
      },
      "source": [
        "model.evaluate(xs, ys)\n",
        "model.evaluate(xs_val, ys_val)\n",
        "model.evaluate(xs_val_differnt, ys_val_different)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 3.6612e-06\n",
            "32/32 [==============================] - 0s 955us/step - loss: 3.7533e-06\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 1.3584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3583735227584839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}