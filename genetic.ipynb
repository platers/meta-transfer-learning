{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sdi2UTA8vWEJ"
   },
   "source": [
    "A proof of concept showing using a genetic algorithm with our environment.\n",
    "It is similar to https://github.com/DEAP/deap/blob/a0b78956e28387785e3bb6e2b4b1f1b32c2b3883/examples/ga/onemax_short.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Qv1kWykfqRLl",
    "outputId": "eda4b75a-48ff-4852-a019-b40577db74e0"
   },
   "outputs": [],
   "source": [
    "# Run this cell if you're using colab. Otherwise, skip it.\n",
    "\n",
    "!git clone https://github.com/platers/meta-transfer-learning.git\n",
    "\n",
    "import os\n",
    "os.chdir('meta-transfer-learning')\n",
    "\n",
    "!pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojEPVGZmvTAe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import array\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "import gym\n",
    "\n",
    "from environments import SimpleEnv\n",
    "import importlib\n",
    "importlib.reload(SimpleEnv)\n",
    "from environments.SimpleEnv import SimpleEnv #, TODO: add more environments\n",
    "\n",
    "from ray.rllib.agents import ppo\n",
    "from ray import tune\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.evaluation import MultiAgentEpisode, RolloutWorker\n",
    "from ray.rllib.agents.callbacks import DefaultCallbacks\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 19:16:13,525\tINFO resource_spec.py:212 -- Starting Ray with 2.54 GiB memory available for workers and up to 1.29 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-04 19:16:13,898\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "n_agents = 3\n",
    "n_var = 2\n",
    "training_envs = [(SimpleEnv, {\n",
    "    'n_agents': n_agents,\n",
    "    'n_vars': n_var,\n",
    "    'max_step_count': 20,\n",
    "})]\n",
    "test_env = (SimpleEnv, {\n",
    "    'n_agents': n_agents,\n",
    "    'n_vars': n_var,\n",
    "    'max_step_count': 20,\n",
    "})\n",
    "\n",
    "creator.create('FitnessMax', base.Fitness, weights=(1.0, ))\n",
    "creator.create('Individual', array.array, typecode='d',\n",
    "               fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register('attr', random.uniform, -1, 1)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual,\n",
    "                 toolbox.attr, n_agents * n_var)\n",
    "toolbox.register('population', tools.initRepeat, list,\n",
    "                 toolbox.individual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "oP1G3iuuolJi",
    "outputId": "d957997c-cf69-42eb-c90c-91a90fdaa8be"
   },
   "outputs": [],
   "source": [
    "def evaluate_individual_env(individual, environment, env_config):\n",
    "    \"\"\"Runs the environment. All agents have the same policy.\n",
    "  It returns the total true reward as the fitness.\n",
    "  \"\"\"\n",
    "    #Select random individuals from pop and create the reward weights\n",
    "    pop = np.array([individual for i in range(n_agents)])\n",
    "    reward_weights = pop\n",
    "    #print(individual, reward_weights)\n",
    "    env_config['reward_weights'] = reward_weights\n",
    "    #env is only to get action space and observation space\n",
    "    env = environment(config=env_config)\n",
    "    class MyCallbacks(DefaultCallbacks):\n",
    "        #Callback functions to keep track of true reward while training\n",
    "        def on_episode_start(self, worker: RolloutWorker, base_env: BaseEnv,\n",
    "                         policies: Dict[str, Policy],\n",
    "                         episode: MultiAgentEpisode, **kwargs):\n",
    "            episode.user_data[\"true_rewards\"] = np.zeros(n_agents)\n",
    "\n",
    "        def on_episode_step(self, worker: RolloutWorker, base_env: BaseEnv,\n",
    "                        episode: MultiAgentEpisode, **kwargs):\n",
    "            env = base_env\n",
    "            true_reward = env.env_states[0].env.last_true_reward\n",
    "            episode.user_data[\"true_rewards\"] += true_reward\n",
    "\n",
    "        def on_episode_end(self, worker: RolloutWorker, base_env: BaseEnv,\n",
    "                       policies: Dict[str, Policy], episode: MultiAgentEpisode,\n",
    "                       **kwargs):\n",
    "            true_reward = episode.user_data[\"true_rewards\"]\n",
    "            for i, r in enumerate(true_reward):\n",
    "                episode.custom_metrics[\"true_reward_agent_\" + str(i)] = r\n",
    "            \n",
    "    config={\n",
    "        \"multiagent\": {\n",
    "            \"policies\": {\n",
    "            },\n",
    "            \"policy_mapping_fn\":  #all agents share a policy\n",
    "                lambda agent_id:\n",
    "                    'agent'\n",
    "        },\n",
    "        'env_config': env_config,\n",
    "        \"callbacks\": MyCallbacks,\n",
    "    }\n",
    "    config['multiagent']['policies']['agent'] = (None, env.observation_space, env.action_space, {})\n",
    "    trainer = ppo.PPOTrainer(env=environment, config=config)\n",
    "    \n",
    "    true_reward_mean = 0\n",
    "    for i in range(10):\n",
    "        #print('TRAINING', i)\n",
    "        true_reward_mean = 0\n",
    "        custom_metrics = trainer.train()['custom_metrics']  # distributed training step\n",
    "        #print(custom_metrics)\n",
    "        for i in range(n_agents):\n",
    "            true_reward_mean += custom_metrics['true_reward_agent_' + str(i) + '_mean']\n",
    "    true_reward_mean /= n_agents\n",
    "    #print('true reward', trainer.collect_metrics()['custom_metrics']['true_reward_mean'])\n",
    "    print('Evaluated', individual, 'Fitness', true_reward_mean)\n",
    "    return true_reward_mean\n",
    "\n",
    "\n",
    "def evaluate_individual(individual):\n",
    "    \"\"\"Runs all environments. \n",
    "  returns the average true reward over all environments as the fitness.\n",
    "  \"\"\"\n",
    "    fitness = 0\n",
    "    for env, config in training_envs:\n",
    "        fitness += evaluate_individual_env(individual, env, config)\n",
    "    return (fitness, )\n",
    "    \n",
    "toolbox.register('evaluate', evaluate_individual)\n",
    "toolbox.register('mate', tools.cxTwoPoint)\n",
    "toolbox.register('mutate', tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register('select', tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "k1cp_IzAwg5n",
    "outputId": "fc500615-efde-4668-e94a-685f9ef3df07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 19:16:14,812\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-05-04 19:16:14,934\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n",
      "2020-05-04 19:16:14,941\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18945)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=18945)\u001b[0m   from ._conv import register_converters as _register_converters\n",
      "\u001b[2m\u001b[36m(pid=18944)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=18944)\u001b[0m   from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 19:16:24,129\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-04 19:16:24,129\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "2020-05-04 19:20:02,937\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated array('d', [-0.7809296114190265, -0.3162295926872183, 0.8804039548963456, -0.9110896525697714, 0.582323916736595, -0.2089458281705452]) Fitness 18.504254030637767\n",
      "\u001b[2m\u001b[36m(pid=18943)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=18943)\u001b[0m   from ._conv import register_converters as _register_converters\n",
      "\u001b[2m\u001b[36m(pid=18946)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=18946)\u001b[0m   from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 19:20:10,992\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-04 19:20:10,995\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "2020-05-04 19:23:48,966\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated array('d', [0.8048936748469211, -0.42136636738971034, -0.5471091157689494, -0.32437253226948504, 0.8913376278294656, -0.5156219725609816]) Fitness 9.757477083435516\n",
      "\u001b[2m\u001b[36m(pid=19361)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=19361)\u001b[0m   from ._conv import register_converters as _register_converters\n",
      "\u001b[2m\u001b[36m(pid=19362)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=19362)\u001b[0m   from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 19:23:57,466\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-04 19:23:57,470\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "2020-05-04 19:27:40,930\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated array('d', [-0.8123258034521932, -0.588649071285352, -0.029361298526450863, 0.14840465326327656, -0.8290937720667428, -0.6923058316154422]) Fitness -3.650540992602449\n",
      "gen\tnevals\tavg    \tstd    \tmin     \tmax    \n",
      "0  \t3     \t8.20373\t9.11114\t-3.65054\t18.5043\n",
      "\u001b[2m\u001b[36m(pid=19372)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=19372)\u001b[0m   from ._conv import register_converters as _register_converters\n",
      "\u001b[2m\u001b[36m(pid=19495)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=19495)\u001b[0m   from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 19:27:49,316\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-04 19:27:49,319\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "2020-05-04 19:30:54,610\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated array('d', [-0.7809296114190265, -0.3162295926872183, 0.8804039548963456, -0.9110896525697714, 0.582323916736595, -0.2089458281705452]) Fitness 7.828378641099239\n",
      "\u001b[2m\u001b[36m(pid=19584)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=19584)\u001b[0m   from ._conv import register_converters as _register_converters\n",
      "\u001b[2m\u001b[36m(pid=19587)\u001b[0m /home/victor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\u001b[2m\u001b[36m(pid=19587)\u001b[0m   from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 19:31:03,304\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-04 19:31:03,306\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "pop = toolbox.population(n=3)\n",
    "hof = tools.HallOfFame(10)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register('avg', np.mean)\n",
    "stats.register('std', np.std)\n",
    "stats.register('min', np.min)\n",
    "stats.register('max', np.max)\n",
    "\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=3, \n",
    "                                   stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "print ('pop', pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_individual = hof[0]\n",
    "print(best_individual)\n",
    "\n",
    "test_reward = evaluate_individual_env(best_individual, test_env[0], test_env[1])\n",
    "print(test_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate_individual([0, 0, 1, 0, 1, 0])) #Ideal reward, altruistic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate_individual([1, 0, -1, 0, -1, 0])) #Worst reward, selfish agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "genetic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
